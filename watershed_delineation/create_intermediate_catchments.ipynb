{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52d7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c47db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from pyproj import CRS\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd45a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook:\n",
    "# 1. Cleans the watersheds shapefile by getting rid of very small polygons on edges\n",
    "# 2. Creates intermediate catchments (delineation B) using the watersheds shapefile from delineation A\n",
    "# and the gauge hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab629fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def subtract_catchments(watershed_gdf, current_id, upstream_id):\n",
    "    # Get the geometry of the two polygons\n",
    "    polygon1 = watershed_gdf.loc[int(current_id)].geometry\n",
    "    polygon2 = watershed_gdf.loc[int(upstream_id)].geometry\n",
    "\n",
    "    # Create a temporary GeoDataFrame with the polygon geometry\n",
    "    temp_gdf = gpd.GeoDataFrame(geometry=[polygon1], crs=watershed_gdf.crs)\n",
    "\n",
    "    # Perform the overlay operation\n",
    "    subtracted_geometry = gpd.overlay(temp_gdf, gpd.GeoDataFrame(geometry=[polygon2], crs=watershed_gdf.crs), how='difference').geometry.values[0]\n",
    "\n",
    "    # Create a new GeoDataFrame with the subtracted geometry\n",
    "    subtracted_gdf = gpd.GeoDataFrame(geometry=[subtracted_geometry], crs=watershed_gdf.crs)\n",
    "\n",
    "    # Check the resulting GeoDataFrame\n",
    "    return(subtracted_gdf)\n",
    "\n",
    "def subtract_joined_catchments(watershed_gdf, current_id, joined_catchments_geom):\n",
    "    polygon1 = watershed_gdf.loc[int(current_id)].geometry\n",
    "    polygon2 = joined_catchments_geom\n",
    "    \n",
    "    # Create a temporary GeoDataFrame with the polygon geometry\n",
    "    temp_gdf = gpd.GeoDataFrame(geometry=[polygon1], crs=watershed_gdf.crs)\n",
    "\n",
    "    # Perform the overlay operation\n",
    "    subtracted_geometry = gpd.overlay(temp_gdf, gpd.GeoDataFrame(geometry=[polygon2], crs=watershed_gdf.crs), how='difference').geometry.values[0]\n",
    "\n",
    "    # Create a new GeoDataFrame with the subtracted geometry\n",
    "    subtracted_gdf = gpd.GeoDataFrame(geometry=[subtracted_geometry], crs=watershed_gdf.crs)\n",
    "\n",
    "    # Check the resulting GeoDataFrame\n",
    "    return(subtracted_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ac0e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_gdf = gpd.read_file(Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\watersheds\\final_watersheds\\watersheds.shp\"))\n",
    "watershed_gdf.index = watershed_gdf['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66a2b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original watersheds shapefile\n",
    "watershed_gdf = gpd.read_file(Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\watersheds\\final_watersheds\\watersheds.shp\"))\n",
    "watershed_gdf.index = watershed_gdf['index']\n",
    "\n",
    "# Now we need to clean the watersheds shapefile - some watersheds are of the type \"multipolygon\"\n",
    "# We loop through all watersheds and for multipolygons, we select only the largest polygon\n",
    "\n",
    "# Create an empty list to store the basin geometries\n",
    "basin_geometries = []\n",
    "basin_ids = []\n",
    "# Loop through all polygons in the GeoDataFrame\n",
    "for index, row in watershed_gdf.iterrows():\n",
    "    # print(index)\n",
    "    geometry = row['geometry']\n",
    "    \n",
    "    # Check if the geometry is a MultiPolygon\n",
    "    if geometry.geom_type == 'MultiPolygon':\n",
    "        # Find the largest polygon within the MultiPolygon\n",
    "        \n",
    "        # Initialize variables to store the largest polygon information\n",
    "        largest_polygon = None\n",
    "        largest_area = 0\n",
    "\n",
    "        # Iterate over the individual polygons within the MultiPolygon\n",
    "        for polygon in geometry.geoms:\n",
    "            # Calculate the area of the current polygon\n",
    "            polygon_area = polygon.area\n",
    "            # Check if the current polygon has a larger area than the previous largest polygon\n",
    "            if polygon_area > largest_area:\n",
    "                largest_polygon = polygon\n",
    "                largest_area = polygon_area\n",
    "\n",
    "        # Create a GeoSeries with the largest polygon\n",
    "        largest_polygon_series = gpd.GeoSeries([largest_polygon])\n",
    "        # Create a GeoDataFrame with the largest polygon\n",
    "        largest_polygon_gdf = gpd.GeoDataFrame(geometry=largest_polygon_series)\n",
    "        \n",
    "        basin_geometries.append(largest_polygon)\n",
    "    else:\n",
    "        basin_geometries.append(geometry)\n",
    "    basin_ids.append(index)\n",
    "    \n",
    "# Create a list of tuples containing the polygon geometries and indices\n",
    "features = [(Polygon(geometry), index) for geometry, index in zip(basin_geometries, basin_ids)]\n",
    "\n",
    "# Create a GeoDataFrame from the features list\n",
    "basin_gdf = gpd.GeoDataFrame(features, columns=['geometry', 'index'])\n",
    "\n",
    "# Specify the CRS\n",
    "crs = CRS.from_epsg(3057)\n",
    "\n",
    "# Set the CRS of the GeoDataFrame\n",
    "basin_gdf.crs = crs\n",
    "\n",
    "# save as shapefile\n",
    "savepath = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\watersheds\\final_watersheds\\watersheds_cleaned_no_multipolygons.shp\")\n",
    "basin_gdf.to_file(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6892f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the updated catchment shapefile back in, as well as a .csv file with the gauge hierarchy\n",
    "watershed_gdf = gpd.read_file(Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\watersheds\\final_watersheds\\final_watersheds\\Basins_A.shp\"))\n",
    "watershed_gdf.index = watershed_gdf['index']\n",
    "gauge_df = pd.read_csv(Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\lamah_ice\\B_basins_intermediate_all\\1_attributes\\Gauge_hierarchy.csv\"),sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f16fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n",
      "length is >1\n"
     ]
    }
   ],
   "source": [
    "# Now we loop through and create intermediate catchments\n",
    "basin_geometries = []  # Initialize a list to store basin geometries\n",
    "basin_ids = []\n",
    "for _, row in gauge_df.iterrows():\n",
    "    upstream_gauge = row[\"NEXTUPID\"]\n",
    "    downstream_gauge = row[\"NEXTDOWNID\"]\n",
    "    upstream_gauge = upstream_gauge.split(',')\n",
    "    if upstream_gauge == ['0']:\n",
    "        # If there is no upstream gauge, start with the current gauge's catchment\n",
    "        basin_geom = watershed_gdf[watershed_gdf[\"index\"] == row[\"ID\"]].geometry.iloc[0]\n",
    "    \n",
    "    elif len(upstream_gauge)>1:\n",
    "        print('length is >1')\n",
    "        number_indices = [int(index) for index in upstream_gauge]\n",
    "        merged_geometry = watershed_gdf.loc[watershed_gdf['index'].isin(number_indices), 'geometry']\n",
    "        merged_polygon = unary_union(merged_geometry)\n",
    "        basin_geom = subtract_joined_catchments(watershed_gdf, row.ID, merged_polygon)\n",
    "\n",
    "    else:\n",
    "        upstream_gauge = upstream_gauge[0]\n",
    "        # Subtract the catchment of the upstream gauge from the basin geometry\n",
    "        basin_geom = subtract_catchments(watershed_gdf, row.ID, upstream_gauge)\n",
    "    # If the resulting geometry is a multipolygon, we repeat the process of eliminating small polygons\n",
    "    if basin_geom.geom_type[0] == 'MultiPolygon':\n",
    "        # Initialize variables to store the largest and second largest polygon information\n",
    "        largest_polygon = None\n",
    "        largest_area = 0\n",
    "        second_largest_polygon = None\n",
    "        second_largest_area = 0\n",
    "\n",
    "        multi_polygon = basin_geom.loc[0, 'geometry']\n",
    "\n",
    "        # Iterate over the individual polygons within the MultiPolygon\n",
    "        for polygon in multi_polygon.geoms:\n",
    "            # Calculate the area of the current polygon\n",
    "            polygon_area = polygon.area\n",
    "\n",
    "            # Check if the current polygon has a larger area than the previous largest polygon\n",
    "            if polygon_area > largest_area:\n",
    "                second_largest_polygon = largest_polygon\n",
    "                second_largest_area = largest_area\n",
    "                largest_polygon = polygon\n",
    "                largest_area = polygon_area\n",
    "            # Check if the current polygon has a larger area than the second largest polygon\n",
    "            elif polygon_area > second_largest_area:\n",
    "                second_largest_polygon = polygon\n",
    "                second_largest_area = polygon_area\n",
    "\n",
    "        if row.ID in [100,88]:\n",
    "            # Note: This is hardcoded in because watersheds 100 and 88 had other, larger polygons that were not correct.\n",
    "            basin_geom = second_largest_polygon\n",
    "        else:\n",
    "            basin_geom = largest_polygon\n",
    "\n",
    "    if isinstance(basin_geom, gpd.GeoDataFrame):\n",
    "        basin_geom = basin_geom.geometry[0]\n",
    "\n",
    "    basin_geometries.append(basin_geom)  # Add the updated basin geometry to the list\n",
    "    basin_ids.append(row.ID)\n",
    "    \n",
    "# Create a list of tuples containing the polygon geometries and indices\n",
    "\n",
    "# Assuming you have a list of geometries called 'basin_geometries' and a corresponding list of indices called 'basin_ids'\n",
    "features = []\n",
    "for geometry, index in zip(basin_geometries, basin_ids):\n",
    "    # Check if the geometry is valid before adding it to the features list\n",
    "    if isinstance(geometry, Polygon):\n",
    "        features.append((geometry, index))\n",
    "    else:\n",
    "        print('The geometry for ID %s is not actually a geometry' % index)\n",
    "#         print(hi)\n",
    "\n",
    "# Create the GeoDataFrame\n",
    "basin_gdf = gpd.GeoDataFrame(features, columns=['geometry', 'index'])\n",
    "\n",
    "# Specify the CRS\n",
    "crs = CRS.from_epsg(3057)\n",
    "\n",
    "# Set the CRS of the GeoDataFrame\n",
    "basin_gdf.crs = crs\n",
    "\n",
    "# save as shapefile\n",
    "savepath = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\watersheds\\final_watersheds\\intermediate_watersheds_08242023_v8.shp\")\n",
    "basin_gdf.to_file(savepath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lamah_py311]",
   "language": "python",
   "name": "conda-env-lamah_py311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
