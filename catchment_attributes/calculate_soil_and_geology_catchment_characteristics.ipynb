{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39f1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ea95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import rasterio.plot\n",
    "import rasterio.mask\n",
    "import geopandas as gpds\n",
    "import fiona\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pds\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27254f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "geo_NI_path = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\glim_geology\\NI_geology_isn_93.shp\")\n",
    "# # Basins A\n",
    "# combined_wsheds_path = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\watersheds\\final_watersheds\\final_watersheds\\Basins_A.shp\")\n",
    "# # Define the save paths\n",
    "# save_path_soils = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\lamah_ice\\A_basins_total_upstrm\\1_attributes\\final_attributes\\soil_attrs_basins_A.csv\")\n",
    "# save_path_NI_geo = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\lamah_ice\\A_basins_total_upstrm\\1_attributes\\final_attributes\\NI_geo_attrs_basins_A.csv\")\n",
    "\n",
    "# Basins B\n",
    "combined_wsheds_path = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\watersheds\\final_watersheds\\final_watersheds\\Basins_B.shp\")\n",
    "# Define the save paths\n",
    "save_path_soils = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\lamah_ice\\B_basins_intermediate_all\\1_attributes\\soil_attrs_basins_B.csv\")\n",
    "save_path_NI_geo = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\lamah_ice\\B_basins_intermediate_all\\1_attributes\\NI_geo_attrs_basins_B.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7a4c1",
   "metadata": {},
   "source": [
    "# ESSD soil properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e23ea828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -3.4028234663852886e+38, 'width': 452, 'height': 302, 'count': 1, 'crs': CRS.from_epsg(3057), 'transform': Affine(1327.5220196902653, 0.0, 185128.0905,\n",
      "       0.0, -1328.6797526490066, 688067.6015)}\n"
     ]
    }
   ],
   "source": [
    "# First we create a variable called nodata\n",
    "path = path = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\european_soil_database_derived_data\\ESDD_processed_data_reprojection_in_QGIS\\%s_depth_weighted_average.tif\" % 'clay_fra') #nodata_set_to_nan\n",
    "with rio.open(path) as dataset:\n",
    "    print(dataset.meta)\n",
    "nodata = dataset.meta['nodata']\n",
    "\n",
    "# First we process 'clay_fra','grav_fra','soil_tawc','oc_fra', 'silt_fra','soil_poros','root_dep' and 'sand_fra'\n",
    "wsheds = gpds.read_file(combined_wsheds_path)\n",
    "wsheds = wsheds.set_index('id')\n",
    "\n",
    "# Bý til lista með nöfnum sem verða dict keys:\n",
    "var_list = ['clay_fra','grav_fra','soil_tawc','oc_fra',\n",
    "            'silt_fra','soil_poros','root_dep','sand_fra']\n",
    "final_dict = dict()\n",
    "\n",
    "for var in var_list:\n",
    "    \n",
    "    path = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\european_soil_database_derived_data\\ESDD_processed_data_reprojection_in_QGIS\\%s_depth_weighted_average.tif\" % var) #nodata_set_to_nan\n",
    "    src = rio.open(path)\n",
    "\n",
    "    var_dict = dict()\n",
    "    for idx in wsheds.index:\n",
    "        # Clip raster with the watershed shapefile\n",
    "        out_image, out_transform = rasterio.mask.mask(src, [wsheds.loc[idx]['geometry']], crop=True)\n",
    "        out_meta = src.meta\n",
    "\n",
    "        rster = out_image[0]\n",
    "        rster = rster[rster != nodata] #, np.nan]\n",
    "        var_dict[idx] = np.nanmean(rster)\n",
    "\n",
    "        #print('idx %s done' % idx)\n",
    "    final_dict[var] = var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75e2c74a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bedrock depth:\n",
    "# Now we process the last remaining variable, bedrock depth\n",
    "# In this case, we are only computing the mean sediment thickness of the land surface that is not covered by lakes or glaciers\n",
    "\n",
    "var = 'bedrk_dep'\n",
    "\n",
    "path = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\european_soil_database_derived_data\\ESDD_processed_data_reprojection_in_QGIS\\average_soil_and_sedimentary-deposit_thickness_nodata_is_255_clipped_isn93.tif\")\n",
    "\n",
    "src = rio.open(path)\n",
    "\n",
    "var_dict = dict()\n",
    "for idx in wsheds.index:\n",
    "    # Clip raster with the watershed shapefile\n",
    "    out_image, out_transform = rasterio.mask.mask(src, [wsheds.loc[idx]['geometry']], crop=True)\n",
    "    out_meta = src.meta\n",
    "\n",
    "    rster = out_image[0]\n",
    "    rster = rster[rster != nodata] #, np.nan]\n",
    "    rster = rster[rster != 255]\n",
    "    var_dict[idx] = np.nanmean(rster)\n",
    "\n",
    "    #print('idx %s done' % idx)\n",
    "final_dict[var] = var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b15670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_df = pds.DataFrame(final_dict)\n",
    "# Convert from % to fraction, and root dep from cm to m\n",
    "soil_df[['clay_fra','grav_fra','oc_fra','silt_fra','sand_fra','root_dep']]/=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246216cb",
   "metadata": {},
   "source": [
    "# Geology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b0113ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the polygon shapefiles\n",
    "polygons = gpds.read_file(combined_wsheds_path)\n",
    "polygons = polygons.set_index('id')\n",
    "polygons['ID'] = polygons.index\n",
    "values = gpds.read_file(geo_NI_path)\n",
    "# Perform an intersection between the two shapefiles\n",
    "intersection = gpds.overlay(polygons, values, how='intersection')\n",
    "\n",
    "# Calculate the area of the intersection for each polygon/field combination\n",
    "intersection['area'] = intersection.geometry.area\n",
    "\n",
    "# Calculate the total area of each polygon\n",
    "polygons['total_area'] = polygons.geometry.area\n",
    "\n",
    "# Calculate the portion of each polygon covered by each field value\n",
    "portions = intersection.groupby(['ID', 'FLOKKUR'])['area'].sum() / polygons.set_index('ID')['total_area']\n",
    "\n",
    "# Reshape the portions data into a pivot table with fields as columns and polygons as rows\n",
    "portions_table = portions.unstack(level='FLOKKUR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860e6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = portions_table.fillna(0).round(3)\n",
    "largest_col = portions_table.apply(lambda x: x.idxmax(), axis=1)\n",
    "df_dominant_class = pds.DataFrame(largest_col)\n",
    "column_names = ['g%s_fra' % i for i in geo_df.columns]\n",
    "geo_df.columns = column_names\n",
    "geo_df['g_dom_NI'] = df_dominant_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b41c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as .csv\n",
    "soil_df.round(3).to_csv(save_path_soils)\n",
    "geo_df.round(3).to_csv(save_path_NI_geo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lamah_py311]",
   "language": "python",
   "name": "conda-env-lamah_py311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
