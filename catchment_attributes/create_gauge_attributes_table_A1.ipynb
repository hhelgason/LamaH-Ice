{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "identical-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "robust-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "pds.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3574cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the following columns:\n",
    "# ID, name, river, elev, lon, lat, country, obsbeg_d, obsend_d, obsbeg_h, obsend_h, gaps_h, typimpact, \n",
    "# degimpact, hierarchy, nextdownid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa83c4c",
   "metadata": {},
   "source": [
    "# First we compute the fraction of gaps and start and end dates for unfiltered daily and hourly streamflow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee1b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read streamflow pickle files\n",
    "save_date = 'july20'\n",
    "savepath = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\discharge_measurements\\processed_by_hh\\combined_gauges_LV_VI_raw_%s.p\" % save_date)\n",
    "combined_dict_npc_met_office = pickle.load(open( savepath, \"rb\" ) )\n",
    "savepath = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\discharge_measurements\\processed_by_hh\\combined_gauges_LV_VI_raw_splitted_%s.p\" % save_date)\n",
    "splitted_gauge_dict = pickle.load(open( savepath, \"rb\" ) )\n",
    "savepath = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\discharge_measurements\\processed_by_hh\\hourly_data_IMO_NPC_%s.p\" % save_date)\n",
    "hourly_dict = pickle.load(open( savepath, \"rb\" ) )\n",
    "savepath = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\discharge_measurements\\processed_by_hh\\combined_gauges_LV_VI_highqual_splitted_%s.p\" % save_date)\n",
    "splitted_gauge_dict_filtered = pickle.load(open( savepath, \"rb\" ) )\n",
    "\n",
    "# Read gauge shapefile\n",
    "gauges_path = Path(r'C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\GIS\\watersheds\\final_watersheds\\gauges_with_splitted_included_with_elevation.shp') \n",
    "gauges = gpd.read_file(gauges_path)\n",
    "gauges = gauges.set_index('id')\n",
    "cols = ['st_numer', 'st_nafn', 'vhm_numer', 'vatnsfall', 'elevation','geometry']\n",
    "gauges_reduced = gauges[cols]\n",
    "gauges_reduced.columns = ['V_no','name','VHM_no','river', 'elevation', 'geometry']\n",
    "# gauges_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee65fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We update the key names in the hourly dict (for splitted gauges)\n",
    "# Lists of old and new key names\n",
    "old_key_names = ['V100', 'V112', 'V68']\n",
    "new_key_names = ['V100_3', 'V112_2', 'V68_2']\n",
    "\n",
    "# Create a new dictionary to store the updated keys\n",
    "updated_hourly_dict = {}\n",
    "\n",
    "# Loop through the old key names and update the keys\n",
    "for old_key, new_key in zip(old_key_names, new_key_names):\n",
    "    if old_key in hourly_dict:\n",
    "        value = hourly_dict.pop(old_key)  # Extract the value of the old key\n",
    "        updated_hourly_dict[new_key] = value  # Add a new entry with the updated key\n",
    "\n",
    "# Add any remaining entries from the original dictionary\n",
    "updated_hourly_dict.update(hourly_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "579456b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create another dict without preceding and trailing nans\n",
    "def drop_nan_boundaries(df):\n",
    "    first_valid_idx = df['Value'].first_valid_index()\n",
    "    last_valid_idx = df['Value'].last_valid_index()\n",
    "    return df.loc[first_valid_idx:last_valid_idx]\n",
    "\n",
    "# We remove nans from the front and back of the hourly series\n",
    "gauge_data_nan_cleaned = dict()\n",
    "for key in updated_hourly_dict.keys():\n",
    "    gauge_data_nan_cleaned[key] = drop_nan_boundaries(updated_hourly_dict[key])\n",
    "    \n",
    "# We remove nans from the front and back of the daily series\n",
    "gauge_data_nan_cleaned_daily = dict()\n",
    "for key in splitted_gauge_dict.keys():\n",
    "    gauge_data_nan_cleaned_daily[key] = drop_nan_boundaries(splitted_gauge_dict[key])\n",
    "    \n",
    "# We remove nans from the front and back of the daily filtered series\n",
    "gauge_data_nan_cleaned_daily_filtered = dict()\n",
    "for key in splitted_gauge_dict_filtered.keys():\n",
    "    gauge_data_nan_cleaned_daily_filtered[key] = drop_nan_boundaries(splitted_gauge_dict_filtered[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c553b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Now we calculate the fraction of missing data:\n",
    "\n",
    "# Create lists to store gauge names and corresponding fraction of missing data\n",
    "gauge_ids = []\n",
    "fraction_missing_list = []\n",
    "\n",
    "for gauge, df in gauge_data_nan_cleaned.items():\n",
    "    gauge_id = gauges_reduced[gauges_reduced['V_no']==gauge].index[0]\n",
    "    # Convert the index to datetime if not already in datetime format\n",
    "    df.index = pds.to_datetime(df.index)\n",
    "    \n",
    "    # Calculate the total number of hours and the number of missing hours\n",
    "    total_hours = len(df)\n",
    "    missing_hours = df['Value'].isna().sum()\n",
    "    \n",
    "    # Calculate the fraction of missing data in percentage\n",
    "    fraction_missing = (missing_hours / total_hours) * 1000\n",
    "    \n",
    "    # Append gauge name and fraction of missing data to the lists\n",
    "    gauge_ids.append(gauge_id)\n",
    "    fraction_missing_list.append(fraction_missing)\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "gaps_df = pds.DataFrame({'gaps_hourly': fraction_missing_list}, index=gauge_ids)\n",
    "gaps_df = gaps_df.sort_index()\n",
    "gauges_reduced['gaps_hourly'] = gaps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a37ff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# add latitude and longitude columns\n",
    "gauges_reduced['lat'] = gauges.geometry.apply(lambda p: int(p.y))\n",
    "gauges_reduced['lon'] = gauges.geometry.apply(lambda p: int(p.x))\n",
    "\n",
    "# replace NaNs in VHM_no with -1\n",
    "gauges_reduced['VHM_no'] = pds.to_numeric(gauges_reduced['VHM_no'] , errors='coerce')\n",
    "gauges_reduced['VHM_no']  = gauges_reduced['VHM_no'].fillna(-1)\n",
    "\n",
    "# convert the column to integer data type\n",
    "gauges_reduced['VHM_no'] = gauges_reduced['VHM_no'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81890e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Now we calculate the obsbeg and obsend\n",
    "\n",
    "# First we process daily streamflow\n",
    "indices = []\n",
    "beginning_year = []\n",
    "end_year = []\n",
    "for idx in gauges_reduced.index:\n",
    "    gauge = gauges_reduced.loc[idx]['V_no']\n",
    "    if gauge in ['V100','V68','V112']:\n",
    "        gauge=gauge+'_1'\n",
    "    beginning_year.append(gauge_data_nan_cleaned_daily[gauge].index[0].year)\n",
    "    end_year.append(gauge_data_nan_cleaned_daily[gauge].index[-1].year)\n",
    "    indices.append(idx)\n",
    "    \n",
    "df = pds.DataFrame({'obsbeg_day': beginning_year,\n",
    "                   'obsend_day': end_year},\n",
    "                  index=indices)\n",
    "gauges_reduced['obsbeg_day'] = df['obsbeg_day']\n",
    "gauges_reduced['obsend_day'] = df['obsend_day']\n",
    "\n",
    "# Now we process the hourly streamflow:\n",
    "indices = []\n",
    "beginning_year = []\n",
    "end_year = []\n",
    "for idx in gauges_reduced.index:\n",
    "    gauge = gauges_reduced.loc[idx]['V_no']\n",
    "    try:\n",
    "        beginning_year.append(gauge_data_nan_cleaned[gauge].index[0].year)\n",
    "        end_year.append(gauge_data_nan_cleaned[gauge].index[-1].year)\n",
    "    except:\n",
    "#         print('No hourly data for ID %s, %s' % (idx,gauge))\n",
    "        beginning_year.append(-1)\n",
    "        end_year.append(-1)\n",
    "    indices.append(idx)\n",
    "    \n",
    "df = pds.DataFrame({'obsbeg_hr': beginning_year,\n",
    "                   'obsend_hr': end_year},\n",
    "                  index=indices)\n",
    "gauges_reduced['obsbeg_hr'] = df['obsbeg_hr']\n",
    "gauges_reduced['obsend_dr'] = df['obsend_hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98c455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read gauge hierarchy and human impact .csv files\n",
    "human_infl_path = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\lamah_ice\\A_basins_total_upstrm\\1_attributes\\final_attributes\\human_influence_cleaned_reordered.csv\")\n",
    "influence = pds.read_csv(human_infl_path,sep='\\t',encoding='UTF-16')\n",
    "influence = influence.set_index('id')\n",
    "\n",
    "hierarchy_path = Path(r\"C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\lamah_ice\\B_basins_intermediate_all\\1_attributes\\Gauge_hierarchy.csv\")\n",
    "hier = pds.read_csv(hierarchy_path,sep=';')\n",
    "hier = hier.set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c0090f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "gauges_reduced['typimpact'] = influence['typimpact']\n",
    "gauges_reduced['degimpact'] = influence['Degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aea8b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hordurbhe\\AppData\\Local\\anaconda3_\\envs\\lamah_py311\\Lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "gauges_reduced['country'] = 'ISL'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15642399",
   "metadata": {},
   "source": [
    "# Export gauge attributes table as .csv and .shp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32eb2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(r\"C:\\Users\\hordurbhe\\Documents\\Vinna\\lamah\\lamah_ice\\lamah_ice\\D_gauges\\1_attributes\\Gauge_attributes.csv\")\n",
    "gauges_reduced[['V_no','name','river','VHM_no',\n",
    "       'gaps_hourly',  'obsbeg_day', 'obsend_day', 'obsbeg_hr',\n",
    "       'obsend_dr', 'typimpact', 'degimpact','elevation','lat', 'lon','geometry']].to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f65a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hordurbhe\\AppData\\Local\\Temp\\ipykernel_10400\\186795243.py:6: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  'obsend_dr', 'typimpact', 'degimpact','elevation','lat', 'lon','geometry']].to_file(save_path)\n"
     ]
    }
   ],
   "source": [
    "# Also save a final version of the gauges shapefile\n",
    "gauges_reduced.crs = 'EPSG:3057'\n",
    "save_path = Path(r\"C:\\Users\\hordurbhe\\Documents\\Vinna\\lamah\\lamah_ice\\lamah_ice\\D_gauges\\3_shapefiles\\gauges.shp\")\n",
    "gauges_reduced[['V_no','name','river','VHM_no',\n",
    "       'gaps_hourly',  'obsbeg_day', 'obsend_day', 'obsbeg_hr',\n",
    "       'obsend_dr', 'typimpact', 'degimpact','elevation','lat', 'lon','geometry']].to_file(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lamah_py311]",
   "language": "python",
   "name": "conda-env-lamah_py311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
