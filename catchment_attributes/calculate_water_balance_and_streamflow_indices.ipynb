{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prescription-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ready-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook reads streamflow measurements and meteorological data\n",
    "# and exports a dataframe with water balance statistics and streamflow indices.\n",
    "# Winter streamflow data is missing for some years. Only years with >90% temporal data coverage are considered.\n",
    "# Gauges with less than 3 years of valid data are omitted.\n",
    "# We consider two versions of the streamflow observations: Unfiltered data (all measurements) and filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "17975ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\hordurbhe\\Dropbox\\UW\\lamah_ice\\code\\HydroAnalysis')\n",
    "import hydroanalysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpds\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import hydroanalysis.utils\n",
    "import hydroanalysis.streamflow_signatures\n",
    "\n",
    "# Set the lamah-ice path\n",
    "path_lamahice = Path(r\"C:\\Users\\hordurbhe\\Documents\\Vinna\\lamah\\lamah_ice\\lamah_ice\")\n",
    "\n",
    "# Define common file paths\n",
    "path_gauges = path_lamahice / \"D_gauges/3_shapefiles/gauges.shp\"\n",
    "path_catchment_attrs = path_lamahice / \"A_basins_total_upstrm/1_attributes/Catchment_attributes.csv\"\n",
    "path_meteorological = path_lamahice / \"A_basins_total_upstrm/2_timeseries/daily/meteorological_data\"\n",
    "savepath_attributes = path_lamahice / \"A_basins_total_upstrm/1_attributes\"\n",
    "savepath_signatures = path_lamahice / \"D_gauges/1_attributes\"\n",
    "\n",
    "# Read gauges shapefile\n",
    "gauges = gpds.read_file(path_gauges)\n",
    "gauges.index = gauges['id'].astype(int)\n",
    "gauges.index.name = 'id'\n",
    "gauges.sort_index(inplace=True)\n",
    "\n",
    "# Read catchment attributes\n",
    "catchment_attrs = pd.read_csv(path_catchment_attrs, sep=';')\n",
    "catchment_attrs.set_index('id', inplace=True)\n",
    "\n",
    "# Add latitude and longitude from the gauges shapefile\n",
    "catchment_attrs['lat'] = gauges.geometry.y\n",
    "catchment_attrs['lon'] = gauges.geometry.x\n",
    "\n",
    "def process_streamflow_data(path_gauges_ts, water_balance_filename, hydro_indices_filename, unfiltered=False):\n",
    "    \"\"\"Process streamflow data and save water balance and hydrological indices.\n",
    "\n",
    "    Parameters:\n",
    "    - path_gauges_ts: Path to the streamflow measurement files (filtered/unfiltered).\n",
    "    - water_balance_filename: Name of the water balance CSV output.\n",
    "    - hydro_indices_filename: Name of the hydrological indices CSV output.\n",
    "    - Unfiltered: Specifies how we convert the quality flag.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store processed measurements\n",
    "    meas_dict = {}\n",
    "\n",
    "    # Loop through gauge files\n",
    "    for gauge_file in path_gauges_ts.glob(\"ID_*.csv\"):\n",
    "        catchment_id = gauge_file.stem.split(\"_\")[1]  # Extract ID\n",
    "        df = pd.read_csv(gauge_file, sep=\";\")\n",
    "\n",
    "        # Convert to datetime index\n",
    "        df['date'] = pd.to_datetime(df[['YYYY', 'MM', 'DD']].astype(str).agg('-'.join, axis=1))\n",
    "        df.set_index('date', inplace=True)\n",
    "\n",
    "        # Rename columns\n",
    "        df = df.rename(columns={'qobs': 'Value', 'qc_flag': 'Quality'})\n",
    "\n",
    "        # Convert quality flag: 0 (good), 1 (bad)\n",
    "        if unfiltered:\n",
    "            df.loc[df['Quality']<=200, 'Quality']=0\n",
    "            df.loc[df['Quality']>200, 'Quality']=1\n",
    "        else:\n",
    "            df['Quality'] = np.where(df['Quality'] > 100, 1, 0)\n",
    "\n",
    "        # Store in dictionary\n",
    "        meas_dict[catchment_id] = df\n",
    "\n",
    "    # Dictionary to store processed hydrological data\n",
    "    data_for_valid_years = {}\n",
    "    valid_years_lengths = {}\n",
    "\n",
    "    # Threshold for valid years\n",
    "    thresh = 0.9\n",
    "\n",
    "    # Time range\n",
    "    start = '1981-10-01'\n",
    "    end = '2018-09-30'\n",
    "\n",
    "    # Loop through catchments\n",
    "    for catchment_id in list(meas_dict.keys()):\n",
    "        df = meas_dict[catchment_id].copy()\n",
    "\n",
    "        # Load corresponding meteorological data\n",
    "        meteo_file = path_meteorological / f\"ID_{catchment_id}.csv\"\n",
    "        if not meteo_file.exists():\n",
    "            continue  # Skip if no meteorological data available\n",
    "\n",
    "        meteo_df = pd.read_csv(meteo_file, sep=\";\")\n",
    "\n",
    "        # Convert to datetime index\n",
    "        meteo_df['date'] = pd.to_datetime(meteo_df[['YYYY', 'MM', 'DD']].astype(str).agg('-'.join, axis=1))\n",
    "        meteo_df.set_index('date', inplace=True)\n",
    "\n",
    "        # Rename meteorological columns\n",
    "        meteo_df = meteo_df.rename(columns={\n",
    "            'prec': 'P_ERA5L',\n",
    "            'pet': 'PET_ERA5L',\n",
    "            'total_et': 'ET_ERA5L',\n",
    "            'prec_rav': 'P_rav',\n",
    "            'ref_et_rav': 'PET_rav',\n",
    "            'total_et_rav': 'ET_rav'\n",
    "        })\n",
    "\n",
    "        # Merge streamflow data with meteorological data\n",
    "        df = df.join(meteo_df[['P_ERA5L', 'PET_ERA5L', 'ET_ERA5L', 'P_rav', 'PET_rav', 'ET_rav']], how=\"left\")\n",
    "        df = df[start:end]\n",
    "\n",
    "        # Compute water year\n",
    "        df['water_year'] = [(d - dt.timedelta(days=273)).year for d in df.index]\n",
    "\n",
    "        # Find years with enough valid data\n",
    "        valid_years = df.dropna().groupby('water_year')['Value'].count() / 365\n",
    "        valid_years = valid_years[valid_years >= thresh]\n",
    "\n",
    "        # Filter for valid years\n",
    "        df_valid = df[df['water_year'].isin(valid_years.index)].copy()\n",
    "\n",
    "        # Convert streamflow to mm/day\n",
    "        catchment_area = catchment_attrs.loc[int(catchment_id)]['area_calc']\n",
    "        df_valid['Q'] = 1000 * (df_valid['Value'] * 86400 / (catchment_area * 1000000))\n",
    "\n",
    "        if len(valid_years) >= 3:\n",
    "            data_for_valid_years[catchment_id] = df_valid[['Q', 'Quality', 'P_ERA5L', 'PET_ERA5L', 'ET_ERA5L', 'water_year', 'P_rav', 'PET_rav', 'ET_rav']]\n",
    "\n",
    "        valid_years_lengths[catchment_id] = {'year_count': len(valid_years)}\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    valid_years_df = pd.DataFrame(valid_years_lengths).T\n",
    "\n",
    "    # Save water balance data\n",
    "    wb_dict = {cid: df.mean() for cid, df in data_for_valid_years.items()}\n",
    "    wb_df = pd.DataFrame(wb_dict).T\n",
    "    wb_df.index.name = 'id'\n",
    "    wb_df.index = wb_df.index.astype(int)\n",
    "    wb_df = wb_df.sort_index()\n",
    "    wb_df[['Q', 'P_ERA5L', 'PET_ERA5L', 'ET_ERA5L', 'P_rav', 'PET_rav', 'ET_rav']].to_csv(savepath_attributes / water_balance_filename, sep=\";\")\n",
    "\n",
    "    # Calculate hydrological signatures\n",
    "    signs_dict = {}\n",
    "    for catchment_id, df in data_for_valid_years.items():\n",
    "        try:\n",
    "            signs_dict[catchment_id] = hydroanalysis.utils.calculate_multiple_signatures([\n",
    "                hydroanalysis.streamflow_signatures.calculate_q_mean,\n",
    "                hydroanalysis.streamflow_signatures.calculate_runoff_ratio,\n",
    "                hydroanalysis.streamflow_signatures.calculate_stream_elas,\n",
    "                hydroanalysis.streamflow_signatures.calculate_slope_fdc,\n",
    "                hydroanalysis.streamflow_signatures.calculate_baseflow_index,\n",
    "                hydroanalysis.streamflow_signatures.calculate_hfd_mean,\n",
    "                hydroanalysis.streamflow_signatures.calculate_q_5,\n",
    "                hydroanalysis.streamflow_signatures.calculate_q_95,\n",
    "                hydroanalysis.streamflow_signatures.calculate_high_q_freq_dur,\n",
    "                hydroanalysis.streamflow_signatures.calculate_low_q_freq_dur,\n",
    "                hydroanalysis.streamflow_signatures.calculate_zero_q_freq\n",
    "            ], df['Q'].values, df['Quality'].values, df['P_rav'].values, df['water_year'].values)\n",
    "        except TypeError:\n",
    "            print(f\"Signature calculation failed for {catchment_id}\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    signs_df = pd.DataFrame(signs_dict).T\n",
    "    signs_df.index.name = 'id'\n",
    "    signs_df.index = signs_df.index.astype(int)\n",
    "    signs_df = signs_df.sort_index()\n",
    "    \n",
    "    # Rename columns\n",
    "    signs_df = signs_df.rename(columns={\n",
    "    'calculate_q_mean': 'q_mean',\n",
    "    'calculate_runoff_ratio': 'runoff_ratio',\n",
    "    'calculate_stream_elas_Sankarasubramanian': 'stream_elas',\n",
    "    'calculate_slope_fdc_Addor': 'slope_fdc',\n",
    "    'calculate_baseflow_index': 'baseflow_index_ladson',\n",
    "    'calculate_hfd_mean_hfd_mean': 'hfd_mean',\n",
    "    'calculate_q_5': 'Q5',\n",
    "    'calculate_q_95': 'Q95',\n",
    "    'calculate_high_q_freq_dur_hq_freq': 'high_q_freq',\n",
    "    'calculate_high_q_freq_dur_hq_dur': 'high_q_dur',\n",
    "    'calculate_low_q_freq_dur_lq_freq': 'low_q_freq',\n",
    "    'calculate_low_q_freq_dur_lq_dur': 'low_q_dur',\n",
    "    'calculate_zero_q_freq': 'zero_q_freq'\n",
    "    })\n",
    "\n",
    "\n",
    "    # Save hydrological indices\n",
    "    signs_df[['q_mean','runoff_ratio','stream_elas',\n",
    "                    'slope_fdc','baseflow_index_ladson',\n",
    "                    'hfd_mean','Q5',\n",
    "                    'Q95','high_q_freq','high_q_dur','low_q_freq',\n",
    "                    'low_q_dur','zero_q_freq']].to_csv(savepath_signatures / hydro_indices_filename, sep=\";\")\n",
    "\n",
    "# Process filtered measurements\n",
    "process_streamflow_data(\n",
    "    path_gauges_ts=path_lamahice / \"D_gauges/2_timeseries/daily_filtered\",\n",
    "    water_balance_filename=\"water_balance.csv\",\n",
    "    hydro_indices_filename=\"hydro_indices_1981_2018.csv\"\n",
    ")\n",
    "\n",
    "# Process unfiltered measurements\n",
    "process_streamflow_data(\n",
    "    path_gauges_ts=path_lamahice / \"D_gauges/2_timeseries/daily\",\n",
    "    water_balance_filename=\"water_balance_unfiltered.csv\",\n",
    "    hydro_indices_filename=\"hydro_indices_1981_2018_unfiltered.csv\",\n",
    "    unfiltered=True\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kiwis]",
   "language": "python",
   "name": "conda-env-kiwis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
